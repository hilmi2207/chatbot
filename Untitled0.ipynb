{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPT5WB6m7csTgUpUP7HY42/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hilmi2207/chatbot/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpyrOWPYdXw1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences as Pad\n",
        "import re\n",
        "import numpy as np\n",
        "import json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVr5vnvadhAk"
      },
      "source": [
        "lines = open('DatasetGabung.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBRoKFstdwhP",
        "outputId": "fc232d67-43eb-456f-d8be-60057ae760f6"
      },
      "source": [
        "# classify questions and answers\n",
        "\n",
        "questions = []\n",
        "answers = []\n",
        "for i in range(len(lines)):\n",
        "    if i % 2 == 0:\n",
        "        questions.append(lines[i])\n",
        "    if i % 2 != 0:\n",
        "        answers.append(lines[i])\n",
        "print(questions[0])\n",
        "print(answers[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nah, mau kita apakan dia?\n",
            "Enaknya dicincang dari mana, ya?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkeAakVEd2bJ"
      },
      "source": [
        "def clean_text(text):\n",
        "\n",
        "    # remove unnecessary characters in sentences\n",
        "    \n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"what is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"there's\", \"there is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r'[\" \"]+', \" \", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M545z0CleMJt",
        "outputId": "f6395fa8-38cc-4de2-95a3-5a20974ed2a3"
      },
      "source": [
        "clean_questions = []\n",
        "for question in questions: \n",
        "    clean_questions.append(clean_text(question))\n",
        "    \n",
        "clean_answers = []\n",
        "for answer in answers:\n",
        "    answer = 'bos ' + clean_text(answer) +' eos' # add bos (beginning of sentence) and eos (end of sentence) to answers\n",
        "    clean_answers.append(answer)\n",
        "del clean_questions[-1]\n",
        "\n",
        "print(clean_questions[0])\n",
        "print(clean_answers[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nah mau kita apakan dia\n",
            "bos enaknya dicincang dari mana ya eos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtRN-59ReO1B",
        "outputId": "dd518773-03d7-48d0-82ad-0fe96789ff02"
      },
      "source": [
        "print('number of questions: ' + str(len(clean_questions)))\n",
        "print('number of answers: ' + str(len(clean_answers)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of questions: 7717\n",
            "number of answers: 7717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCEiwGKSeZ1p",
        "outputId": "ae23f63e-b614-4eb9-b559-11d8d0a362be"
      },
      "source": [
        "# to make the model easier to experiment, we remove some queries and replies that are too long or too short\n",
        "\n",
        "minlen = 2\n",
        "maxlen = 20\n",
        "filtered_questions_temp = []\n",
        "filtered_answers_temp = []\n",
        "\n",
        "# filter the Q&A pairs which question are too long or too short\n",
        "for i, question in enumerate(clean_questions):\n",
        "    if len(question.split()) <= maxlen and len(question.split()) >= minlen:\n",
        "        filtered_questions_temp.append(question)\n",
        "        filtered_answers_temp.append(clean_answers[i])\n",
        "        \n",
        "filtered_questions = []\n",
        "filtered_answers = []\n",
        "\n",
        "# from 'filtered_questions_temp' and 'filtered_answers_temp' filter the pairs that answers are too long or too short\n",
        "for i, answer in enumerate(filtered_answers_temp):\n",
        "    if len(answer.split()) <= maxlen and len(answer.split()) >= minlen:\n",
        "        filtered_answers.append(answer)\n",
        "        filtered_questions.append(filtered_questions_temp[i])\n",
        "        \n",
        "print(len(filtered_answers))\n",
        "print(len(filtered_questions))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6794\n",
            "6794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBqe3Ovnee-v",
        "outputId": "e702b8ff-c88f-43bd-97da-331001cc4d22"
      },
      "source": [
        "print(filtered_answers[0])\n",
        "print(filtered_questions[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bos enaknya dicincang dari mana ya eos\n",
            "nah mau kita apakan dia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7_Ih8QFe5ZV"
      },
      "source": [
        "# build the input index sequence & vocabulary; build the output index sequence & vocabulary\n",
        "\n",
        "# we build 2 different vocabulary because it is convinient, some other code only use one\n",
        "# this method is also used in machine translation model because we need 2 different vocabulary in different language\n",
        "\n",
        "# define the tokenizer\n",
        "vocabsize = 8000\n",
        "\n",
        "# vocabulary size is 8000, and we use UNK to replace those words are not frequently used\n",
        "question_tokenizer = Tokenizer(num_words = vocabsize+1, oov_token = 'unk')\n",
        "answer_tokenizer = Tokenizer(num_words = vocabsize+1,oov_token = 'unk')\n",
        "\n",
        "# tokenize the questions and answers\n",
        "question_tokenizer.fit_on_texts(filtered_questions)\n",
        "answer_tokenizer.fit_on_texts(filtered_answers)\n",
        "\n",
        "# build the input sequence and output sequence\n",
        "q_sequences = question_tokenizer.texts_to_sequences(filtered_questions)\n",
        "a_sequences = answer_tokenizer.texts_to_sequences(filtered_answers)\n",
        "\n",
        "# pad sequences in same length so that we can train them in model\n",
        "q_pad = Pad(q_sequences, padding = 'post')\n",
        "a_pad = Pad(a_sequences, padding = 'post')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FK1rfzufWAd"
      },
      "source": [
        "# save the preprocessed data\n",
        "q_token_json = question_tokenizer.to_json()\n",
        "a_token_json = answer_tokenizer.to_json()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buUHdpuOfZ0r"
      },
      "source": [
        "with open('questions.json', 'w', encoding='utf-8') as f:\n",
        "    f.write(json.dumps(q_token_json, ensure_ascii=False))\n",
        "    f.close()\n",
        "\n",
        "with open('answers.json', 'w', encoding='utf-8') as f:\n",
        "    f.write(json.dumps(a_token_json, ensure_ascii=False))\n",
        "    f.close()\n",
        "\n",
        "np.savez('data.npz', q_pad, a_pad)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i33yntS2ff5Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}